# Image-Caption-Generation
Welcome to my Bachelor's thesis project, "Image Caption Generation"! This project was developed using a combination of powerful machine learning frameworks Keras and TensorFlow, with a focus on implementing the model using VGG16 pretrained model (for image processing) and LSTM framework (to handle to image labels/captions).

The goal of this project was to develop an image captioning system that is capable of generating natural and meaningful descriptions of images. The system is trained on a large dataset of images and corresponding captions, using the VGG16 model to extract relevant features from the images, and LSTM framework to generate descriptive sentences. 

This project is a great showcase of the power of machine learning and deep learning in the multiple fields of Image rocessing and Natural Language Processing (multi-modal approach). With this system, you can generate accurate and meaningful captions for a wide variety of images, from scenic landscapes to everyday objects.

We have used the Flickr 8K dataset here, which you can download from [kaggle](https://www.kaggle.com/datasets/adityajn105/flickr8k).


This is how exactly our model works:
![image](https://user-images.githubusercontent.com/53014490/230788384-56231c6d-01fb-44db-b7a1-9e0104eb81b5.png)

If you're interested in learning more about image captioning, deep learning, or just want to explore the code behind this project, feel free to explore this repository. Thank you for your interest, and happy coding! 



 
